{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Exercise_7_1_Decision-tree-classifier.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guliko24/CE880_Lab_Work/blob/main/Week7/Exercise_7_1_Decision_tree_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPauStFMQqsN"
      },
      "source": [
        "# CE880: An Approachable Introduction to Data Science\n",
        "### Prepared by: Haider Raza (h.raza@essex.ac.uk)\n",
        "### Approximate time: 120 minutes\n",
        "\n",
        "***\n",
        "## Learning Outcome\n",
        "\n",
        "* Decision Tree\n",
        "***\n",
        "# Introduction to Decision Tree algorithm\n",
        "\n",
        "A Decision Tree algorithm is one of the most popular machine learning algorithms. It uses a tree like structure and their possible combinations to solve a particular problem. It belongs to the class of supervised learning algorithms where it can be used for both classification and regression purposes.\n",
        "\n",
        "A decision tree is a structure that includes a root node, branches (decision nodes), and leaf nodes. Each internal node denotes a test on an attribute, each branch denotes the outcome of a test, and each leaf node holds a class label. The topmost node in the tree is the root node."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZEidYzKQqsO"
      },
      "source": [
        "### Decision-Tree terminology\n",
        "\n",
        "![Decision-Tree terminology](https://gdcoder.com/content/images/2019/05/Screen-Shot-2019-05-18-at-03.40.41.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smFZrxE4QqsR"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt # data visualization\n",
        "import seaborn as sns # statistical data visualization\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCr5sjB4QqsT",
        "outputId": "87697355-9e0d-48e7-d7b3-a5240bf4a027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "data = '/content/car_evaluation.csv'\n",
        "df = pd.read_csv(data, header=None)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/car_evaluation.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c37eae930e00>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/car_evaluation.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/car_evaluation.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG4o0M9VQqsT"
      },
      "source": [
        "# view dimensions of dataset\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr7_Ny4FQqsT"
      },
      "source": [
        "We can see that there are 1728 instances and 7 variables in the data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9LnbYpTQqsT"
      },
      "source": [
        "### View top 5 rows of dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "ttxqXL4jQqsT"
      },
      "source": [
        "# preview the dataset\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0KZdXo2QqsU"
      },
      "source": [
        "### Rename column names\n",
        "\n",
        "We can see that the dataset does not have proper column names. The columns are merely labelled as 0,1,2.... and so on. We should give proper names to the columns. I will do it as follows:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuNV2kb7QqsU"
      },
      "source": [
        "col_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
        "df.columns = col_names\n",
        "col_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1avD8QOQqsU"
      },
      "source": [
        "# let's again preview the dataset\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Sj6eKe0QqsU"
      },
      "source": [
        "We can see that the column names are renamed. Now, the columns have meaningful names."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A48cFbJvQqsU"
      },
      "source": [
        "### View summary of dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Zx29PM4QqsV"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgPqYT-IQqsV"
      },
      "source": [
        "### Frequency distribution of values in variables\n",
        "\n",
        "Now, I will check the frequency counts of categorical variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYyl5C4HQqsV"
      },
      "source": [
        "col_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
        "for col in col_names:\n",
        "    print(df[col].value_counts())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzy9b6KyQqsV"
      },
      "source": [
        "We can see that the `doors` and `persons` are categorical in nature. So, I will treat them as categorical variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIhHf7B-QqsV"
      },
      "source": [
        "### Summary of variables\n",
        "\n",
        "\n",
        "- There are 7 variables in the dataset. All the variables are of categorical data type.\n",
        "\n",
        "\n",
        "- These are given by `buying`, `maint`, `doors`, `persons`, `lug_boot`, `safety` and `class`.\n",
        "\n",
        "\n",
        "- `class` is the target variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4ea1U7UQqsV"
      },
      "source": [
        "### Explore `class` variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoWL1v6cQqsV"
      },
      "source": [
        "df['class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThuBNzTKQqsW"
      },
      "source": [
        "The `class` target variable is ordinal in nature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N17KHTVYQqsW"
      },
      "source": [
        "### Missing values in variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXfWcBPbQqsW"
      },
      "source": [
        "# check missing values in variables\n",
        "\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyOuSGcuQqsW"
      },
      "source": [
        "We can see that there are no missing values in the dataset. I have checked the frequency distribution of values previously. It also confirms that there are no missing values in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKlCcQBPQqsW"
      },
      "source": [
        "# Declare feature vector and target variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cshj_gdJQqsW"
      },
      "source": [
        "X = df.drop(['class'], axis=1)\n",
        "y = df['class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGUpFycfQqsX"
      },
      "source": [
        "# Split data into separate training and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts_jl4aLQqsX"
      },
      "source": [
        "# split X and y into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giqmNF8xQqsX"
      },
      "source": [
        "# check the shape of X_train and X_test\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_87ne-qQqsX"
      },
      "source": [
        "# Feature Engineering\n",
        "\n",
        "**Feature Engineering** is the process of transforming raw data into useful features that help us to understand our model better and increase its predictive power. I will carry out feature engineering on different types of variables.\n",
        "\n",
        "First, I will check the data types of variables again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rhqDV3NQqsX"
      },
      "source": [
        "# check data types in X_train\n",
        "X_train.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "semsXBwrQqsX"
      },
      "source": [
        "### Encode categorical variables\n",
        "\n",
        "\n",
        "Now, I will encode the categorical variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qAWZAziQqsX"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCQHqHJcQqsY"
      },
      "source": [
        "We can see that all  the variables are ordinal categorical data type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxz1zTR_QqsY"
      },
      "source": [
        "# import category encoders\n",
        "!pip install category-encoders\n",
        "import category_encoders as ce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DyTOgAUQqsY"
      },
      "source": [
        "# encode variables with ordinal encoding\n",
        "encoder = ce.OrdinalEncoder(cols=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])\n",
        "X_train = encoder.fit_transform(X_train)\n",
        "X_test = encoder.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uQpWdKdQqsY"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJADYS1kQqsY"
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoqKrF9HQqsY"
      },
      "source": [
        "We now have training and test set ready for model building."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofn3xgeyQqsY"
      },
      "source": [
        "## Decision Tree Classifier with criterion gini index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pok223n1QqsY"
      },
      "source": [
        "# import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3ajywJ_QqsZ"
      },
      "source": [
        "# instantiate the DecisionTreeClassifier model with criterion gini index\n",
        "clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=0)\n",
        "# fit the model\n",
        "clf_gini.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr_GOJzPQqsZ"
      },
      "source": [
        "### Predict the Test set results with criterion gini index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90ZbUnVPQqsZ"
      },
      "source": [
        "y_pred_gini = clf_gini.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5Bq-e37QqsZ"
      },
      "source": [
        "### Check accuracy score with criterion gini index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PVLglGfQqsZ"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print('Model accuracy score with criterion gini index: {0:0.4f}'. format(accuracy_score(y_test, y_pred_gini)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkTGfF2_QqsZ"
      },
      "source": [
        "Here, **y_test** are the true class labels and **y_pred_gini** are the predicted class labels in the test-set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0phsZS9QqsZ"
      },
      "source": [
        "### Compare the train-set and test-set accuracy\n",
        "\n",
        "\n",
        "Now, I will compare the train-set and test-set accuracy to check for overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nOMzCftQqsZ"
      },
      "source": [
        "y_pred_train_gini = clf_gini.predict(X_train)\n",
        "y_pred_train_gini"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZS2UKAHQqsa"
      },
      "source": [
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train_gini)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQf9BYtPQqsa"
      },
      "source": [
        "### Check for overfitting and underfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbkD6qxEQqsa"
      },
      "source": [
        "# print the scores on training and test set\n",
        "print('Training set score: {:.4f}'.format(clf_gini.score(X_train, y_train)))\n",
        "print('Test set score: {:.4f}'.format(clf_gini.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm22K_JEQqsa"
      },
      "source": [
        "Here, the training-set accuracy score is 0.7865 while the test-set accuracy to be 0.8021. These two values are quite comparable. So, there is no sign of overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmJrlS5mQqsa"
      },
      "source": [
        "### Visualize decision-trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlZFJVFEQqsa"
      },
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "from sklearn import tree\n",
        "tree.plot_tree(clf_gini.fit(X_train, y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYUJMYZWQqsa"
      },
      "source": [
        "### Visualize decision-trees with graphviz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQVdebVFQqsa"
      },
      "source": [
        "import graphviz\n",
        "dot_data = tree.export_graphviz(clf_gini, out_file=None,\n",
        "                              feature_names=X_train.columns,\n",
        "                              class_names=y_train,\n",
        "                              filled=True, rounded=True,\n",
        "                              special_characters=True)\n",
        "\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}